---
title: "09_wipt"
author: "Michaela Gustafson"
date: "1/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## TIME REMOVAL ANALYSIS: WILLOW PTARMIGAN

In this code I will be running my time-removal abundance model for Willow Ptarmigan.

This is a multinomial N-mixture model.


## Willow Ptarmigan Habitat

Citation:
Hannon, S. J., P. K. Eason, and K. Martin (2020). Willow Ptarmigan (Lagopus lagopus), version 1.0. In Birds of the World (S. M. Billerman, Editor). Cornell Lab of Ornithology, Ithaca, NY, USA. https://doi.org/10.2173/bow.wilpta.01

Habitat: During the breeding season, Willow Ptarmigan inhabit subarctic and subalpine habitats where there is abundant shrubby vegetation, usually places below 6,000 feet elevation. At this season, they favor flat, moist areas as opposed to steep, dry slopes. Common plants are willow, birch, spruce, and fir; crowberry and blueberry are also present in some parts of the breeding range. 

Food: Willow Ptarmigan have a simple diet of plant matter, primarily flower buds, catkins, leaves, twigs, berries, and seeds. In summer, they also eat whatever insects are available, both from the ground and low vegetation. Specific plant foods include willow, blueberry, bearberry, horsetail, birch, poplar, avens, Viburnum (arrowwood), and seeds of various grasses and sedges. 



## LIBRARY
These are the packages used in the following code:
```{r library}
library(dplyr)
library(tidyverse)
library(ggplot2)
library(unmarked)
library(AICcmodavg)
library(raster)
library(here)
library(AHMbook)
```


## LOAD OBSERVATION and ENVIRONMENTAL DATA

```{r loaddata}

all.obs <- read.csv(here("E:/gyrf_analysis/gyrf3/output/obs_3years.csv"))
all.env2 <- read.csv(here("E:/gyrf_analysis/gyrf3/output/final_env_join_22Aug22.csv"))

# remove extra 'X' column from import
all.obs <- all.obs[,-c(1)]
all.env2 <- all.env2[,-c(1)]

for (i in 1:nrow(all.env2)) {
   all.env2$shrub[i] <- all.env2$openshrub[i] + all.env2$tallshrub[i]
}

for (i in 1:nrow(all.env2)) {
   all.env2$allshrub[i] <- all.env2$openshrub[i] + all.env2$tallshrub[i] + all.env2$lowshrub[i]
}

# create frequency tables

#all.env3 <- all.env2[,c(2:16)]



```
## PREP OBSERVATION DATA FOR SELECTED SPECIES

```{r wiptprep}
# copy data table for WIPT

wipt <- data.frame(all.obs)

# change all species codes of WIPT to a 1 and all other species to 0
wipt$species[wipt$species == "WIPT"] <- 1
wipt$species[wipt$species != "1"] <- 0

# change count to 0 for non WIPT
wipt$count[wipt$species == 0] <- 0
head(wipt)
# now 'wipt' df represents counts for Willow Ptarmigan


# check for na values
sum(is.na(wipt$time_int))


# change time intervals to reflect intervals of 2 minutes
wipt2 <- mutate(wipt, 
                time_int = ifelse(wipt$time_int %in% 0:1, "1", 
                                  ifelse(wipt$time_int %in% 2:3, "2", 
                                         ifelse(wipt$time_int %in% 4:5, "3",
                                                ifelse(wipt$time_int %in% 6:7, "4",
                                                       ifelse(wipt$time_int %in% 8:9, "5", "NA"))))))


# aggregate rows and sum counts for matching keys and time intervals
# must change formats first:

str(wipt2)

wipt2$id <- as.factor(wipt2$id)
wipt2$time_int <- as.factor(wipt2$time_int)
wipt2$count <- as.integer(wipt2$count)


sum(wipt2$count) # sample size 528


# get number of sites with counts each year

wipt.19 <- subset(wipt2, year == "2019" & wipt2$count > 0)

sum(wipt.19$count) # 266 obs in 2019
unique(wipt.19$id) # 126 sites in 19

wipt.21 <- subset(wipt2, year == "2021" & wipt2$count > 0)
sum(wipt.21$count) # 252 obs in 2021
unique(wipt.21$id) # 131 sites in 21

wipt.22 <- subset(wipt2, year == "2022" & wipt2$count > 0)
sum(wipt.22$count) # 10 obs in 2022
unique(wipt.22$id) # 6 sites in 22


wipt.agg <- aggregate(x = wipt2$count, 
                      by = list(wipt2$id, wipt2$time_int), 
                      FUN = sum)


sum(wipt.agg$x) # sample size still 528

# rename columns in aggregated df

head(wipt.agg)

names(wipt.agg)[names(wipt.agg) == "Group.1"] <- "id"
names(wipt.agg)[names(wipt.agg) == "Group.2"] <- "time_int"
names(wipt.agg)[names(wipt.agg) == "x"] <- "count"

head(wipt.agg)

sum(wipt.agg$count) # double checking count

# okay so wipt.agg is our count dataframe, we don't need any of the other columns,
# those were only used to help filter out for distance and flyover observatiosn

sum(wipt.agg$count) # sample size: 528

# check that ids are matching between env and obs
# need to change id to a factor to use anti-join
all.env2$id <- as.factor(all.env2$id)
miss1 <- anti_join(all.env2, wipt.agg) # clear
miss2 <- anti_join(wipt.agg, all.env2) # clear



# spread dataframes:

unique(wipt.agg$id) # should end up with 988 rows


wipt.wide <- wipt.agg %>%
  dplyr::select(id, time_int, count) %>%
  spread(key = time_int, value = count, fill = 0)

# double check sample size

ss.check <- wipt.wide %>%
  mutate(all_sum = sum(wipt.wide$'1', wipt.wide$'2' , wipt.wide$'3', wipt.wide$'4', wipt.wide$'5'))

write.csv(wipt.wide, ("E:/gyrf_analysis/gyrf3/output/wiptwide.csv"))
wipt.wide <- read.csv("E:/gyrf_analysis/gyrf3/output/wiptwide.csv")
wipt.wide <- wipt.wide[,-c(1)]


sum(wipt.wide[, 2:6])

```

```{r testvars}
test.df <- left_join(wipt.wide, all.env2)
test.df$total <- rowSums(test.df[,c("1", "2", "3", "4", "5")])

a1 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$sparseveg))
a1 # for ROPT the upper ones might be outliers...above 0.7-75ish?

a2 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$tundra))
a2 #

a4 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$allshrub))
a4 

a5 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$lowshrub))
a5 # possible outliers here for low shrub

a6 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$shrub))
a6 # shrub 

a7 <- ggplot( data = test.df) + geom_histogram( aes_string( fill = (as.factor(test.df$total)), x = test.df$tussock))
a7



```

## TIME-REMOVAL MODEL
WIPT sample size: 516 individuals counted
```{r trframe}
all.env.scaled2 <- read.csv("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/all.env.scaled_06Oct23.csv")
all.env.scaled2 <- all.env.scaled2[,-c(1)]

wipt.env.join <- left_join(wipt.wide, all.env.scaled2)
head(wipt.env.join); dim(wipt.env.join)
str(wipt.env.join)
wipt.env.join$year <- as.factor(wipt.env.join$year)


# create observation and site covariate data frames
colnames(wipt.env.join)

timeints <- wipt.env.join[,c(2:6)]
siCovs <- wipt.env.join[,c(7:31)]
area <- pi*400^2/10000

wiptFrame2 <- unmarkedFrameMPois(
  # import time removal columns(counts):
  y = timeints, 
  siteCovs = data.frame(siCovs, area), 
  # define pifun type: 
  type = "removal" )
# fit models: multinomPois order of formulas: detection, abundance

#creating dataframe for negative binomial model 
umf.nb <- unmarkedFrameGMM( y = timeints, 
  siteCovs = data.frame(siCovs, area),
  type = "removal",
  numPrimary = 1 )

```

```{r trmodel}
# can't use all land cover variables because htey add up to 1 within each site

fm0 <- multinomPois(~ 1 ~ 1, data = wiptFrame2) #null model

fm.2 <- multinomPois( ~ 1 + julian + min_after_sun + wind + observer ~ 1 + tundra + tussock + allshrub + elev + offset(log(area)), data = wiptFrame2)

#fm.6 <- multinomPois( ~ 1 + julian + min_after_sun + wind + observer ~ 1 + tundra + shrub + elev + offset(log(area)), data = wiptFrame2)

#fm.7 <- multinomPois( ~ 1 + julian + min_after_sun + wind + observer ~ 1 + tundra + allshrub + elev + offset(log(area)), data = wiptFrame2)

#negative binomial and ZIP versions

nbm1 <- gmultmix(
  #abundance
  ~ 1 + tundra + tussock + allshrub + elev + offset(log(area)), 
  ~1 ,
  ~ 1 + julian + min_after_sun + wind + observer,
    mixture = "NB",
  umf.nb, engine="R" )

summary(nbm1)

nbm4 <- gmultmix(
  #abundance
  ~ 1 + tundra + tussock + tallshrub + elev + offset(log(area)), 
  ~1 ,
  ~ 1 + julian + min_after_sun + wind + observer,
    mixture = "NB",
  umf.nb, engine="R" )

summary(nbm4)

nbm5 <- gmultmix(
  #abundance
  ~ 1 + tundra + tussock + tallshrub + openshrub + elev + offset(log(area)), 
  ~1 ,
  ~ 1 + julian + min_after_sun + wind + observer,
    mixture = "NB",
  umf.nb, engine="R" )

summary(nbm5)
#rerun the Poisson model for model comparison
nbm2 <- gmultmix(
  #abundance
  ~ 1 + tundra + tussock + allshrub + elev + offset(log(area)), 
  ~1 ,
  ~ 1 + julian + min_after_sun + wind + observer,
    mixture = "P",
  umf.nb, engine="R" )

summary(nbm2)

nbm3 <- gmultmix(
  #abundance
  ~ 1 + tundra + tussock + allshrub + elev + year + offset(log(area)), 
  ~1 ,
  ~ 1 + julian + min_after_sun + wind + observer,
    mixture = "NB",
  umf.nb, engine="R" )

summary(nbm3)

gof.boot.3 <- Nmix.gof.test( nbm3, nsim = 100, print.table = TRUE )


confint(nbm1, type = "lambda")
confint(nbm2, type = "lambda")
confint(fm.2, type = "state")

confint(nbm1, type = "det")

ms2 <- fitList(
  "lam(.)p(.)" = fm0,
  "lam(tundra+tussock+allshrub+elev+offset(log(area)))p(julian+min_after_sun+wind+observer)" = fm.2)


(ms2sel <- modSel(ms2))
ms2sel


summary(fm0)
summary(fm.2)
#summary(fm.6)
#summary(fm.7)


wp.coef <- as.data.frame(coef(nbm1))
wp.state.confint <- as.data.frame(confint(nbm1, level = 0.95, type = "lambda"))
wp.det.confint <- as.data.frame(confint(nbm1, level = 0.95, type = "det"))
write.csv(wp.coef, ("E:/Cruz Lab/03Results/wpcoef.csv"))
write.csv(wp.state.confint, here("E:/Cruz Lab/03Results/wpci_state.csv"))
write.csv(wp.det.confint, here("E:/Cruz Lab/03Results/wpci_det.csv"))


summary(nbm1@estimates[2])
write.csv(summary(nbm1@estimates[1]), "E:/Cruz Lab/03Results/wiptNBsummarylambda.csv")
write.csv(summary(nbm1@estimates[2]), "E:/Cruz Lab/03Results/wiptNBsummarydet.csv")



```



## CHECK MODEL FIT
Will be looking at c-hat for overdispersion, as well as chisq value and its p-value
```{r gof}

set.seed(1234)

#(gof.fm2 <- parboot(object = fm.2, statistic = fitstats2, nsim = 1000, report = 1))
#gof.fm2

#fit stats for NB model
fitstats.nb1 <- function(nbm1) {
  observed <- getY(nbm1@data)
  expected <- fitted(nbm1)
  resids <- residuals(nbm1)
  n.obs <- apply(observed,1,sum,na.rm=TRUE)
  n.pred <- apply(expected,1,sum,na.rm=TRUE)
  sse <- sum(resids^2, na.rm=TRUE)
  chisq <- sum((observed - expected)^2 / expected, na.rm=TRUE)
  freeTuke <- sum((sqrt(observed) - sqrt(expected))^2, na.rm=TRUE)
  freeTuke.n <- sum((sqrt(n.obs)-sqrt(n.pred))^2, na.rm=TRUE)
  sse.n <- sum( (n.obs-n.pred)^2, na.rm=TRUE)
  chisq.n <- sum((n.obs-n.pred)^2/expected, na.rm=TRUE)
  
  out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke, SSE.n=sse.n, Chisq.n=chisq.n, freemanTukey.n=freeTuke.n)
  return(out)
}

(gof.nb1 <- parboot(nbm1, fitstats.nb1, nsim = 1000, report = 1))


print(gof.nb1)


saveRDS(gof.nb1, ("C:/Users/Ryan/OneDrive/Documents/MSgyrfalcon/wipt_gof_13Sep23.rds"))

chat.nb <- gof.nb1@t0[2]/mean(gof.nb1@t.star[,2])
chat.nb # 0.9479961



# compute c-hat
chat.2 <- gof.fm2@t0[2]/mean(gof.fm2@t.star[,2])
chat.2
#1.004

saveRDS(fm.2, "E:/gyrf_analysis/gyrf3/models/wiptfm2_27Aug22.rds")
fm.2 <- readRDS(here("models/wiptfm2_27Aug22.rds"))


```

## PREDICT
Used tundra, tussock, low and tall shrub, and elevation in WIPT model (and include detection variables back in later???)
```{r predict}

# First need to scale study-wide rasters to match scaling of model:


elev <- raster("E:/gyrf_analysis/MSgyrfalcon/dem_1k.tif")
lowshrub <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/lowshrub.tif")
openshrub <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/openshrub.tif")
tallshrub <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/tallshrub.tif")
tundra <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/tundra.tif")
tussock <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/tussock.tif")
tallshrub <- raster("E:/gyrf_analysis/MSgyrfalcon/MSgyrfalcon/1k prediction rasters/tallshrub.tif")


#elev <- raster("E:/gyrf_analysis/gyrf3/output/dem_400.tif")
#lowshrub <- raster("E:/gyrf_analysis/gyrf3/prediction surfaces 17Aug/lowshrub.tif")
#openshrub <- raster("E:/gyrf_analysis/gyrf3/prediction surfaces 17Aug/openshrub.tif")
#tallshrub <- raster("E:/gyrf_analysis/gyrf3/prediction surfaces 17Aug/tallshrub.tif")
#tundra <- raster("E:/gyrf_analysis/gyrf3/prediction surfaces 17Aug/tundra.tif")
#tussock <- raster("E:/gyrf_analysis/gyrf3/prediction surfaces 17Aug/tussock.tif")

allshrub = sum(tallshrub,openshrub,lowshrub,na.rm=TRUE)
#plot(allshrub)
#plot(tallshrub)



area.raster <- elev # CHANGE BACK TO ELEVATION ONCE GET RASTER LAYER
values(area.raster) <- 1000*1000/10000 # area of a grid pixel, divided by 10000 to standardize


# find center/mean and std dev of scaled covariates to scale prediction surfaces above
### NEED TO FIND CENTER AND STD DEV FOR SCALED allshrub###

cellStats(elev, mean) #173.7808
cellStats(elev, "sd") #120.5669

elev.s <- (elev-173.7808)/120.5669

cellStats(allshrub, mean) #0.2130462
cellStats(allshrub, sd)#0.1891451

allshrub.s <- (allshrub-0.2130462)/0.1891451

cellStats(tundra, mean) #0.1608737
cellStats(tundra, sd) #0.08171017

tundra.s <- (tundra-0.1608737)/0.08171017

cellStats(tussock, mean) #0.1202638
cellStats(tussock, sd) #0.08615176

tussock.s <- (tussock-0.1202638)/0.08615176


cellStats(tallshrub, mean)
cellStats(tallshrub, sd)

tallshrub.s <- (tallshrub - 0.1321896)/0.07754615


#elev.s <- (elev-180)/103
#tundra.s <- (tundra-0.573)/0.305
#tussock.s <- (tussock-0.0632)/0.104
#allshrub.s <- (allshrub-0.233)/0.248

# add detection covariates (standardized mean values)

jul.raster <- elev 
values(jul.raster) <- mean(all.env.scaled2$julian)

wind.raster <- elev 
values(wind.raster) <- mean(all.env.scaled2$wind)

minsun.raster <- elev 
values(minsun.raster) <- mean(all.env.scaled2$min_after_sun)

obs.raster <- elev 
values(obs.raster) <- as.factor("DS")



pred.surface <- stack(tundra.s, tussock.s, allshrub.s, elev.s, area.raster, jul.raster, wind.raster, minsun.raster, obs.raster)

names(pred.surface) <- c("tundra", "tussock", "allshrub", "elev", "area", "julian", "wind", "min_after_sun", "observer")

pred.surface4 <- stack(tundra.s, tussock.s, tallshrub.s, elev.s, area.raster, jul.raster, wind.raster, minsun.raster, obs.raster)

names(pred.surface4) <- c("tundra", "tussock", "tallshrub", "elev", "area", "julian", "wind", "min_after_sun", "observer")

wipt.prediction <- predict(nbm1, type="lambda", newdata=pred.surface)

wipt.prediction4 <- predict(nbm4, type="lambda", newdata=pred.surface4)

plot(wipt.prediction4)
cellStats(wipt.prediction4, 'sum')

cellStats(wipt.prediction, 'mean')
cellStats(wipt.prediction, 'median')
plot(wipt.prediction)

#ncell(wipt.prediction)

#wipt.freq <- freq(wipt.prediction, digits = 2)

#wipt.freq1 <- as.data.frame(wipt.freq[1])

#write.csv(wipt.freq1, here("model output/wiptcellcounts.csv"))

writeRaster(wipt.prediction, filename = names(wipt.prediction), bylayer = TRUE, format = "GTiff", overwrite = TRUE)
```



# PREDICTION MAP

```{r wiptpredmap}

library(RColorBrewer)


plot(wipt.prediction, axes=FALSE, col=colorRampPalette(brewer.pal(3,"Blues"))(100))


sum_raster_cells <-cellStats(wipt.prediction, 'sum')
sum_raster_cells

# Extract raster values as a vector
r_values <- getValues(wipt.prediction)

# Define a function to calculate the mean and confidence intervals using bootstrapping
calculate_mean_ci <- function(x, indices) {
  sample_data <- x[indices]
  mean_value <- mean(sample_data, na.rm = TRUE)
  ci <- boot::boot(sample_data, statistic = function(data, indices) {
    mean(data[indices], na.rm = TRUE)
  }, R = 1000)  # You can adjust the number of bootstrap replicates (R) as needed
  ci_summary <- quantile(ci$t, c(0.025, 0.975))
  return(list(mean = mean_value, ci = ci_summary))
}

# Calculate mean and confidence intervals for the entire raster values
result <- calculate_mean_ci(r_values, 1:length(r_values))

# Extract the mean and confidence intervals
mean_value <- result$mean
ci <- result$ci

# Print the mean and confidence intervals
print(mean_value)
print(ci)

cellStats(wipt.prediction, 'mean')

```


Partial Prediction Plots

```{r ppplots}
# Elevation X Willow Ptarm
# All shrub X Willow Ptarm
# Tundra X Willow Ptarm
# Tussock X Willow Ptarm


# Estimate partial prediction plots for predictors with 95% CIs not overlapping zero:
# Start by creating our datasets to predict over

# how many values do we use:
n <- 100

# Use the observed values to define our range:
elevation.pp <- seq( min( all.env2[,"elev"]),max(500),
                   length.out = n )

allshrub.pp <- seq( min( all.env2[,"allshrub"]),max( all.env2[,"allshrub"]),
                   length.out = n )

tundra.pp <- seq( min( all.env2[,"tundra"]),max( all.env2[,"tundra"]),
                   length.out = n )

tussock.pp <- seq( min( all.env2[,"tussock"]),max( all.env2[,"tussock"]),
                   length.out = n )

#standardize predictors:
elev.std <- scale( elevation.pp )
allshrub.std <- scale( allshrub.pp )
tundra.std <- scale( tundra.pp )
tussock.std <- scale( tussock.pp )
area.x = pi*400*400/10000


### ELEVATION

#combine standardized predictors into a new dataframe to predict partial relationship
# for abundance submodel:
abundData <- data.frame( tundra = 0, tussock = 0, allshrub = 0, elev = elev.std, area = area.x )

#predict partial relationship:
pred.elev <- predict( nbm1, type = "lambda", newdata = abundData, 
                          appendData = TRUE )
#view
head( pred.elev ); dim( pred.elev )


### plot

w.elevp <- cbind( pred.elev[,c("Predicted", "lower", "upper") ], elevation.pp ) %>%
  # define x and y values
  ggplot(., aes( x = elevation.pp, y = Predicted ) ) + 
  #choose preset look
  theme_classic( base_size = 15) +
  # add labels
  ylim(0, 13) +
  labs( x = "Elevation (m)", y = "Willow Ptarmigan \n density" ) +
  # add band of confidence intervals
  theme(axis.title.y=element_blank()) +
  theme(text=element_text(size=25)) +
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" )
#view
w.elevp
ggsave("E:/gyrf_analysis/partial prediction plots/wipt_elev.png", width = 20, height = 15, dpi = 300)

```

```{r tussockpp}
### TUSSOCK

#combine standardized predictors into a new dataframe to predict partial relationship
# for abundance submodel:
abundData <- data.frame( tundra = 0, tussock = tussock.std, allshrub = 0, elev = 0, area = area.x )

#predict partial relationship:
pred.tuss <- predict( nbm1, type = "lambda", newdata = abundData, 
                          appendData = TRUE )
#view
head( pred.tuss ); dim( pred.tuss )


### plot

w.tussp <- cbind( pred.tuss[,c("Predicted", "lower", "upper") ], tussock.pp ) %>%
  # define x and y values
  ggplot(., aes( x = tussock.pp, y = Predicted ) ) + 
  #choose preset look
  theme_classic( base_size = 35) +
  # add labels
  ylim(0, 45) +
  # turn x axis into percent scale
  scale_x_continuous(labels = scales::percent_format(accuracy=1)) +
  labs( x = "Tussock", y = "Willow Ptarmigan density" ) +
  # add band of confidence intervals
  theme(text=element_text(size=75)) +
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" )
#view
w.tussp
ggsave("E:/gyrf_analysis/partial prediction plots/wipt_tussock.png", width = 20, height = 15, dpi = 300, limitsize = FALSE)

```

```{r tunpppp}
### TUNDRA

#combine standardized predictors into a new dataframe to predict partial relationship
# for abundance submodel:
abundData <- data.frame( tundra = tundra.std, tussock = 0, allshrub = 0, elev = 0, area = area.x )

#predict partial relationship:
pred.tun <- predict( nbm1, type = "lambda", newdata = abundData, 
                          appendData = TRUE )
#view
head( pred.tun ); dim( pred.tun )


### plot

w.tundp <- cbind( pred.tun[,c("Predicted", "lower", "upper") ], tundra.pp ) %>%
  # define x and y values
  ggplot(., aes( x = tundra.pp, y = Predicted ) ) + 
  #choose preset look
  ylim(0, 45) +
  theme_classic( base_size = 35) +
  # turn x axis into percent scale
  scale_x_continuous(labels = scales::percent_format(accuracy=1)) +
  # add labels
  labs( x = "Tundra", y = "Willow Ptarmigan density" ) +
  # add band of confidence intervals
  theme(text=element_text(size=75)) +
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue")
#view
w.tundp
ggsave("E:/gyrf_analysis/partial prediction plots/wipt_tundra2.png", width = 20, height = 15, dpi = 300)

```

```{r allppp}
### ALL SHRUB

#combine standardized predictors into a new dataframe to predict partial relationship
# for abundance submodel:
abundData <- data.frame( tundra = 0, tussock = 0, allshrub = allshrub.std, elev = 0, area = area.x )

#predict partial relationship:
pred.alls <- predict( nbm1, type = "lambda", newdata = abundData, 
                          appendData = TRUE )
#view
head( pred.alls ); dim( pred.alls )


### plot

w.allsp <- cbind( pred.alls[,c("Predicted", "lower", "upper") ], allshrub.pp ) %>%
  # define x and y values
  ggplot(., aes( x = allshrub.pp, y = Predicted ) ) + 
  #choose preset look
  ylim(0, 45) +
  theme_classic( base_size = 35 ) +
  # turn x axis into percent scale
  scale_x_continuous(labels = scales::percent_format(accuracy=1)) +
  # add labels
  labs( x = "All shrub", y = "Willow Ptarmigan density" ) +
  # add band of confidence intervals
  theme(text=element_text(size= 75)) +
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" )
#view
w.allsp


ggsave("E:/gyrf_analysis/partial prediction plots/wipt_allshrub2.png", width = 20, height = 15,dpi = 300)

```


```{r}
figure <- ggarrange(tundp, allsp,
                    ncol = 3, nrow = 1)


figure
ggsave("wipttundshrub.png", width = 30, height = 8, dpi = 300, limitsize = FALSE)


fig2 <- ggarrange(tussp, elevp,
                    ncol = 3, nrow = 1)
fig2
ggsave("wipttusselev.png", width = 30, height = 8, dpi = 300, limitsize = FALSE)


fig3 <- ggarrange(tundp, allsp, tussp, elevp,
                  ncol = 2, nrow = 2)
fig3



ggsave("wiptall.png", width = 17, height = 17, dpi = 300, limitsize = FALSE)


```


# Partial Prediction Plots for detection covariates

Observer

```{r dppp}
# For detection parameters: julian date, wind spd, min after sun, observer

# Estimate partial prediction plots for predictors with 95% CIs not overlapping zero:
# Start by creating our datasets to predict over

# how many values do we use:
n <- 100


# Use the observed values to define our range:
julian.pp <- seq( min( all.env2[,"julian"]),max(all.env2[,"julian"]),
                   length.out = n )

wind.pp <- seq( min( all.env2[,"wind"]),max( all.env2[,"wind"]),
                   length.out = n )
wind.km <- wind.pp*1.60934

minsun.pp <- seq( min( all.env2[,"min_after_sun"]),max( all.env2[,"min_after_sun"]),
                   length.out = n )


  
### Tutorial Code:
#combine standardized predictor into a new dataframe to predict partial relationship
# with sagebrush. We set observer effect as tech 1
#sageDet <- data.frame( obsv = factor( "tech.1", levels = c("tech.1", "tech.2",
                  #"tech.3", "tech.4") ), sagebrush = sage.std )
  
#now for observer effects:
#obsvDet <- data.frame( obsv = factor( c("tech.1", "tech.2","tech.3", "tech.4"), 
                      # levels = c("tech.1", "tech.2","tech.3", "tech.4") ), 
                     # sagebrush = 0 )
#predict partial relationship between observer effects and detection
#pred.det.obsv <- predict( fm.closed, type = "det", newdata = obsvDet, 
                          #appendData = TRUE )
  

#observer.pp <- seq( min( all.env2[,"min_after_sun"]),max( all.env2[,"min_after_sun"]),
                   #length.out = n ) # how to do partial prediction plot with factor

#standardize predictors:
jul.std <- scale( julian.pp )
wind.std.km <- scale( wind.km )
minsun.std <- scale( minsun.pp )
#area.x = pi*400*400/10000

# Observer effect
#combine standardized predictors into a new dataframe to predict partial relationship
# for abundance submodel:
detDataobs <- data.frame( observer = factor( c("DS", "KW","MG"), levels = c("DS", "KW","MG") ),
                       julian = 0, 
                       wind = 0, 
                       min_after_sun = 0)


#predict partial relationship:
pred.obs <- predict( nbm1, type = "det", newdata = detDataobs, 
                          appendData = TRUE )



obsvp.det <- pred.obs %>%
  # define x and y values
  ggplot(., aes( x = observer, y = Predicted, color = observer ) ) + 
  #choose preset look
  theme_classic( base_size = 35 ) +
  #remove legend
  theme( legend.position = "none" ) +
  # add labels
  labs( x = "Observer", y = "Predicted detection" ) +
  theme(text=element_text(size=75)) +
  #add mean detection for each observer
  geom_point( size = 15 ) +
  # add confidence intervals
  geom_errorbar( aes(ymin = lower, ymax = upper ), 
               size = 4, width = 0.3 ) +
  scale_color_manual(values=c('darkblue','darkblue','darkblue')) +
  ylim(0,0.6)
#view
obsvp.det


ggsave("E:/gyrf_analysis/detection partial plots/wipt_observer.png", width = 15, height = 15, dpi = 300)
```
Julian

```{r detjulp}

detDatajul <- data.frame( observer = factor("DS", levels = c("DS", "KW","MG") ),
                       julian = jul.std, 
                       wind = 0, 
                       min_after_sun = 0)


#predict partial relationship:
pred.jul <- predict( nbm1, type = "det", newdata = detDatajul, 
                          appendData = TRUE )

julp.det <- cbind( pred.jul[,c("Predicted", "lower", "upper") ], julian.pp ) %>%
  # define x and y values
  ggplot(., aes( x = julian.pp, y = Predicted ) ) + 
  #choose preset look
  theme_classic( base_size = 35 ) +
  # add labels
  labs( x = "Julian date", y = "Predicted detection" ) +
  theme(text=element_text(size=75)) +
  # add band of confidence intervals
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" ) +
  ylim(0,.6)
#view
julp.det



ggsave("E:/gyrf_analysis/detection partial plots/wipt_julian.png", width = 15, height = 15, dpi = 300)

```
Wind speed

```{r detwindspp}
detDatawind <- data.frame( observer = factor("DS", levels = c("DS", "KW","MG") ),
                       julian = 0, 
                       wind = wind.std.km, 
                       min_after_sun = 0)


#predict partial relationship:
pred.wind <- predict( nbm1, type = "det", newdata = detDatawind, 
                          appendData = TRUE )

windp.det <- cbind( pred.wind[,c("Predicted", "lower", "upper") ], wind.km ) %>%
  # define x and y values
  ggplot(., aes( x = wind.km, y = Predicted ) ) + 
  #choose preset look
  theme_classic( base_size = 35 ) +
  # add labels
  labs( x = "Wind speed (kph)", y = "Predicted detection" ) +
  theme(text=element_text(size=75)) +
  # add band of confidence intervals
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" ) +
  ylim(0,.6)
#view
windp.det

ggsave("E:/gyrf_analysis/detection partial plots/wipt_wind.png", width = 15, height = 15, dpi = 300)

```

Minutes after sunrise

```{r minaftersunp}

detDatasun <- data.frame( observer = factor("DS", levels = c("DS", "KW","MG") ),
                       julian = 0, 
                       wind = 0, 
                       min_after_sun = minsun.std)


#predict partial relationship:
pred.sun <- predict( nbm1, type = "det", newdata = detDatasun, 
                          appendData = TRUE )

sunp.det <- cbind( pred.sun[,c("Predicted", "lower", "upper") ], minsun.pp ) %>%
  # define x and y values
  ggplot(., aes( x = minsun.pp, y = Predicted ) ) + 
  #choose preset look
  theme_classic( base_size = 35 ) +
  # add labels
  labs( x = "Minutes after sunrise", y = "Predicted detection" ) +
  theme(text=element_text(size=75)) +
  # add band of confidence intervals
  geom_smooth( aes(ymin = lower, ymax = upper ), 
               stat = "identity",
               size = 5, alpha = 0.5, fill = "lightblue3" ) +
  # add mean line on top
  geom_line( size = 5, color = "darkblue" ) +
  ylim(0,.6)
#view
sunp.det


ggsave("E:/gyrf_analysis/detection partial plots/wipt_minsun.png", width = 15, height = 15, dpi = 300)

```




